// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.

// *******************************************************************************************
// NOTE: work in progress rust re-implementation of the prepare-prover-input.py script
//       Many things are not yet working and don't produce the same output  (FIXME)
// *******************************************************************************************

// This program parses a CBOR-encoded mDL and tests extracting the required information
// to generate the ZK circuit inputs.
//
// Usage:
//    prepare-prover-input --config <config> --mdl <mdl> --prover_inputs <prover_inputs>
// where
//    <config> is a JSON file containing the configuration
//    <mdl> is a CBOR-encoded mDL
//    <prover_inputs> is the output JSON file containing the prover inputs
//
// Notes:
//    - The mDL file can be generated by the mdl-gen program
//    - To test: cargo run --bin mdl-test -- --config ../inputs/mdl1/config.json --mdl ../inputs/mdl1/mdl.cbor --prover_inputs ../generated_files/mdl1/prover_inputs.json

use anyhow::Result;
use clap::Parser;
use coset::cbor::Value;
use coset::Label;
use isomdl::cbor;
use isomdl::definitions::helpers::{ByteStr, NonEmptyVec};
use isomdl::definitions::issuer_signed::IssuerSignedItemBytes;
use isomdl::definitions::x509::x5chain::X5CHAIN_COSE_HEADER_LABEL;
use isomdl::definitions::x509::X5Chain;
use isomdl::definitions::{DigestId, IssuerSignedItem, Mso};
use isomdl::issuance::mdoc::Mdoc;
use p256::ecdsa::{Signature, VerifyingKey};
use p256::pkcs8::EncodePublicKey;
use p256::NistP256;
use serde_json::Map;
use sha2::{Digest, Sha256};
use base64::{engine::general_purpose::URL_SAFE_NO_PAD, Engine};
use num_bigint::BigUint;
use num_traits::{Num, Signed};
use chrono::{DateTime, Datelike, FixedOffset, NaiveDate, NaiveDateTime, TimeZone, Utc};
use hex;
use std::str;
use serde::Serialize;
use std::collections::BTreeMap;

static MDL_DOCTYPE: &str = "org.iso.18013.5.1.mDL";
static ISO_MDL_NAMESPACE: &str = "org.iso.18013.5.1";
static AAMVA_MDL_NAMESPACE: &str = "org.iso.18013.5.1.aamva";
static SUPPORTED_NAMESPACES: [&str; 2] = [ISO_MDL_NAMESPACE, AAMVA_MDL_NAMESPACE];


// Define the issuer's timezone as PST (UTC-8). Change this if needed (TODO: move to config?)
const ISSUER_TIMEZONE_OFFSET_HOURS: i32 = -8; // US West Coast / PST (UTC-8)

#[derive(Parser, Debug)]
#[command(author, version, about)]
struct Args {
    /// JSON file containing the config
    #[arg(short = 'c', long = "config")]
    config: String,

    /// JSON file containing the mDL ISO claims
    #[arg(short = 'm', long = "mdl")]
    mdl: String,

    /// output JSON file containing the prover inputs
    #[arg(short = 'i', long = "prover_inputs")]
    prover_inputs: String,
}

fn sha256_padding(prepad_m: &[u8]) -> Vec<u8> {
    let msg_length_bits = (prepad_m.len() * 8) as u32;
    
    // Start with prepad_m and add the 0x80 (128 in decimal) padding byte
    let mut padded_m = prepad_m.to_vec();
    padded_m.push(0x80);

    // Pad with zeros until the total length + 4 bytes (32-bit message length) is a multiple of 64 bytes (512 bits)
    while (padded_m.len() + 4) * 8 % 512 != 0 {
        padded_m.push(0);
    }

    // Append the message length as a 4-byte big-endian value
    padded_m.extend_from_slice(&msg_length_bits.to_be_bytes());

    padded_m
}

fn hex_string_to_binary_array(hex_str: &str, bits: usize) -> Vec<u8> {
    //let binary_string = format!("{:0>bits$b}", u128::from_str_radix(hex_str, 16).unwrap(), bits = bits); FIXME
    let num = BigUint::from_str_radix(hex_str, 16)
    .expect("Invalid hex string");
    let binary_string = format!("{:0>bits$b}", num, bits = bits);    
    binary_string
        .chars()
        .map(|b| b.to_digit(2).unwrap() as u8)
        .collect()
}

fn digest_to_limbs(digest_hex: &str) -> [u128; 2] {
    let digest_bytes = hex::decode(digest_hex).expect("Invalid hex string");
    let n = u128::from_be_bytes(digest_bytes[0..16].try_into().unwrap());
    let b = u128::from_be_bytes(digest_bytes[16..32].try_into().unwrap());
    [n, b]
}

fn base64_decoded_size(encoded_len: usize) -> usize {
    ((encoded_len + 3) / 4) * 3
}

fn ymd_to_timestamp(ymd: &str, is_bytes: bool, has_time: bool) -> Option<u64> {
    let ymd_str = if is_bytes {
        match hex::decode(ymd) {
            Ok(decoded) => match String::from_utf8(decoded) {
                Ok(s) => s,
                Err(_) => return None,
            },
            Err(_) => return None,
        }
    } else {
        ymd.to_string()
    };

    let format_string = if has_time { "%Y-%m-%dT%H:%M:%SZ" } else { "%Y-%m-%d" };
    match NaiveDateTime::parse_from_str(&ymd_str, format_string) {
        Ok(dt) => {
            // Set the correct timezone based on ISSUER_TIMEZONE_OFFSET_HOURS
            // FIXME: not working; I don't get the same value as the python script
            let fixed_offset = FixedOffset::west_opt(ISSUER_TIMEZONE_OFFSET_HOURS * 3600)?;
            let dt_fixed = fixed_offset.from_local_datetime(&dt).single()?;

            // Convert to UTC before getting the timestamp
            let dt_utc: DateTime<Utc> = dt_fixed.with_timezone(&Utc);
            Some(dt_utc.timestamp() as u64)
        }
        Err(_) => None,
    }
}

fn ymd_to_daystamp(ymd: &str) -> Option<i32> {
    let parsed_date = NaiveDate::parse_from_str(ymd, "%Y-%m-%d").ok()?;
    Some(parsed_date.num_days_from_ce())
}

fn extract_valid_until(tbs_data: &[u8]) -> Option<u64> {
    let valid_until_prefix = "6a76616c6964556e74696cc074"; // 6a: text(10), 7661...696c: "validUntil", c0: date, 74: text(20)
    let tbs_data_hex = hex::encode(tbs_data);

    if let Some(valid_until_pos) = tbs_data_hex.find(valid_until_prefix) {
        let valid_until_pos = valid_until_pos + valid_until_prefix.len();
        let valid_until_data = &tbs_data_hex[valid_until_pos..valid_until_pos + 40];

        return ymd_to_timestamp(valid_until_data, true, true);
    }

    None
}

#[derive(Debug)]
struct  ValueDigestInfo {
    value: Value,
    id: DigestId,
    digest: Vec<u8>,
    preimage: ByteStr,
    encoded_l: usize,
    encoded_r: usize,
}

/// Returns (encoded_l, encoded_r) as computed from tbs_data.
///
/// The CBOR format is:
/// - 2-digit hex for the digest id (e.g. "13" for 19)
/// - Literal "5820" for a 32-byte byte string indicator
/// - The 32-byte SHA-256 digest in hex (64 hex digits)
///
/// Then we find the position of this string in the hex-encoded tbs_data. Each byte is 2 hex digits,
/// so we convert the found index to a byte index (by dividing by 2) and subtract 1 (to adjust for a header).
/// Finally, encoded_r is computed as encoded_l + (length of cbored_digest in bytes).
/*
pub fn compute_encoded_positions(
    tbs_data: &[u8],
    id: DigestId,
    digest: &[u8],
) -> Result<(usize, usize), Box<dyn Error>> {
    // Build the "cbored_digest" string.
    // - Format: "{:02x}5820{}", where {:02x} is the digest id in 2-digit hex,
    //   "5820" is a literal string, and the digest is hex-encoded.
    let cbored_digest = format!("{:02x}5820{}", id.0, hex::encode(digest));
    
    // Convert the entire tbs_data into a hex string.
    let tbs_data_hex = hex::encode(tbs_data);
    
    // Find the start position of cbored_digest within tbs_data_hex.
    // This position is in terms of hex characters.
    let pos = tbs_data_hex.find(&cbored_digest)
        .ok_or("cbored_digest not found in tbs_data")?;
    
    // Each byte is represented by 2 hex characters.
    // So, convert the position from hex characters to byte index and subtract 1.
    let encoded_l = (pos / 2).checked_sub(1)
        .ok_or("Invalid encoded_l calculation")?;
    
    // The length of cbored_digest in bytes is its length (in hex characters) divided by 2.
    let encoded_r = encoded_l + (cbored_digest.len() / 2);
    
    Ok((encoded_l, encoded_r))
}
 */

/// Given an mdoc and a target element name, recompute the value digest,
/// compare it with the signed digest in the mso, and return detailed info.
pub fn find_value_digest_info(
    namespaces: &BTreeMap<String, NonEmptyVec<IssuerSignedItemBytes>>,
    mso: &Mso,
    tbs_data: &[u8],
    claim: &str,
) -> Option<ValueDigestInfo> {

    let mut info = ValueDigestInfo {
        value: Value::Null,
        id: DigestId::new(0),
        digest: Vec::new(),
        preimage: ByteStr::from(Vec::new()),
        encoded_l: 0,
        encoded_r: 0,
    };

    // Iterate over each supported namespace.
    let mut found = false;
    for &ns in SUPPORTED_NAMESPACES.iter() {
        if let Some(items) = namespaces.get(ns) {
            // items is a NonEmptyVec<IssuerSignedItemBytes>; iterate over its items.
            for item in items.iter() {
                if item.as_ref().element_identifier != claim {
                    continue;
                }
                println!("found claim: {}", claim);
                found = true;
                println!("item: {:?}", item);

                info.value = item.as_ref().element_value.clone();
                info.id = item.as_ref().digest_id;
                info.preimage = ByteStr::from(serde_cbor::to_vec(item).expect("unable to encode IssuerSigned as cbor bytes"));
                // cbor::to_vec(&item).expect("unable to encode IssuerSigned as cbor bytes");
                let mut hasher = Sha256::new();
                hasher.update(&info.preimage);
                let recomputed_value_digest = hasher.finalize().to_vec();
                let ns_digests = mso.value_digests.get(ns)
                    .ok_or(format!("Namespace {} not found", ns)).unwrap();
                let signed_value_digest = ns_digests.get(&info.id)
                    .ok_or(format!("Signed value digest not found for digest id {:?}", info.id)).unwrap();
                // Compare recomputed digest with the signed digest.
                if recomputed_value_digest != signed_value_digest.as_ref()  {
                    println!("Digest mismatch");
                    println!("Recomputed: {}", hex::encode(&recomputed_value_digest));
                    println!("Signed    : {}", hex::encode(&signed_value_digest));
                } else {
                    println!("Digest: {}", hex::encode(&recomputed_value_digest));
                }
                
                /*
                    let encoded_pos = compute_encoded_positions(tbs_data, info.id, &info.digest).unwrap();
                    info.encoded_l = encoded_pos.0;
                    info.encoded_r = encoded_pos.1;
                 */
                // or should I just ?
                /*
                    // Build the "encoded" digest string.
                    // Format: [digestID (1-byte hex)] + "5820" + [32-byte SHA-256 digest in hex]
                    let cbored_digest = format!("{:02x}5820{}", digest_id, hex::encode(&recomputed_value_digest));

                    // Load the tbs_data from the mdoc.
                    let tbs_data = load_tbs_data(mdoc)?;
                    let tbs_data_hex = hex::encode(&tbs_data);
                    let pos = tbs_data_hex.find(&cbored_digest)
                        .ok_or("cbored_digest not found in tbs_data")?;
                    // Each byte is 2 hex digits; subtract 1 per the original algorithm.
                    let encoded_l = pos / 2;
                    let encoded_l = encoded_l.checked_sub(1)
                        .ok_or("Invalid encoded_l calculation")?;
                    let encoded_r = encoded_l + cbored_digest.len() / 2;
                */

                return Some(info)
            }
        }
    }
    
    println!("Claim not found: {}", claim);
    None
}


fn main() {
    //let args = Args::parse(); // FIXME
    let args = Args {
        config: String::from("../inputs/mdl1/config.json"),
        mdl: String::from("../inputs/mdl1/mdl.cbor"),
        prover_inputs: String::from("../generated_files/mdl1/prover_inputs.json"),
    };

    // read and parse the config file
    let config_file = std::fs::read_to_string(&args.config).unwrap();
    let config: serde_json::Value = serde_json::from_str(&config_file).unwrap();

    let mdl_cbor = std::fs::read(&args.mdl).unwrap();
    let mdoc = cbor::from_slice::<Mdoc>(
        &mdl_cbor)
        .map_err(|_| "Failed to parse mDL")
        .unwrap();

    let doc_type = mdoc.doc_type;
    println!("doc_type: {}\n", doc_type);
    if doc_type != MDL_DOCTYPE {
        panic!("Invalid mDL doc type: {}", doc_type);
    }
    
    // TODO: anything to do with the MSO?
    let mso = mdoc.mso;
    let digest_algorithm = mso.digest_algorithm;
    // TODO: make sure it's SHA-256. Note, the test mdoc.cbor uses "SHA256", and the spec uses "SHA-256".
    //       Are our generation code wrong? Should we be lenient here and ignore case and blanks?
    let value_digests = &mso.value_digests;

    let namespaces = mdoc.namespaces;
    // print all namespaces
    for (key, value) in namespaces.iter() {
        println!("Namespace: {}", key);
        if key != ISO_MDL_NAMESPACE && key != AAMVA_MDL_NAMESPACE { // TODO: replace with SUPPORTED_NAMESPACES
            panic!("Invalid mDL namespace: {}", key);
        }
        println!("Claim count: {}\n", value.len());
    }
    
    let issuer_auth = mdoc.issuer_auth;

    // issuer_auth fields
    let unprotected_header = issuer_auth.unprotected.clone();
    let x5chain = unprotected_header
        .rest
        .iter()
        .find(|(label, _)| label == &Label::Int(X5CHAIN_COSE_HEADER_LABEL))
        .map(|(_, value)| value.to_owned())
        .map(X5Chain::from_cbor)
        .unwrap()
        .unwrap();

    let issuer_pub_key = x5chain.end_entity_public_key::<NistP256>().unwrap();
    println!("issuer_pub_key: {:?}\n", issuer_pub_key);
    let pem = issuer_pub_key
        .to_public_key_pem(Default::default())
        .unwrap();
    println!("PEM formatted public key:\n{}\n", pem);

    /* FIXME: uncomment when not using test data from the old cred.txt
    // per mDL spec, aad is empty
    let empty_aad = Vec::<u8>::new();
    let tbs_data = issuer_auth.inner.tbs_data(&empty_aad);
    */
    // read temp tbs_data from file FIXME: delete this
    let tbs_data = std::fs::read("/home/cpaquin/dev/identity/crescent-credentials/circuit_setup/inputs/mdl1/tbs_data.bin").unwrap();

    // convert tbs_data to a vector of integers
    let tbs_data_ints = tbs_data.to_vec();
    println!("tbs_data_ints length: {:?}\n", tbs_data_ints.len());

    // convert header and payload to UTF-8 integers in base-10 (e.g., 'e' -> 101, 'y' -> 121, ...)
    let padded_m = sha256_padding(&tbs_data_ints);
    let msg_len_after_sha2_padding = padded_m.len();
    println!("msg_len_after_SHA2_padding: {:?}\n", msg_len_after_sha2_padding);

    let config_max_cred_len = config["max_cred_len"].as_u64().unwrap() as usize;
    if msg_len_after_sha2_padding > config_max_cred_len {
        println!(
            "Error: mDL too large. Current mDL header + payload is {} bytes ({} bytes after SHA256 padding), but maximum length supported is {} bytes.",
            tbs_data_ints.len(),
            msg_len_after_sha2_padding,
            base64_decoded_size(config_max_cred_len)
        );
        println!(
            "The config file value `max_cred_len` would have to be increased to {} bytes (currently config['max_cred_len'] = {})",
            tbs_data_ints.len() + 64,
            config_max_cred_len
        );
        std::process::exit(-1);
    }

    let mut padded_m_extended = padded_m.clone();
    while padded_m_extended.len() < config_max_cred_len {
        padded_m_extended.push(0);
    }

    let mut hasher = Sha256::new();
    hasher.update(&tbs_data_ints);
    let sha256_hash = hasher.finalize();

    let digest_hex_str = hex::encode(&sha256_hash);
    let digest_bits = hex_string_to_binary_array(&digest_hex_str, 256);
    let digest_b64 = URL_SAFE_NO_PAD.encode(&sha256_hash);
    let digest_limbs = digest_to_limbs(&digest_hex_str);

    println!("Digest Hex: {}", digest_hex_str);
    println!("Digest Bits: {:?}", digest_bits);
    println!("Digest Base64: {}", digest_b64);
    println!("Digest Limbs: {:?}", digest_limbs);
    
    if let Some(valid_until_unix_timestamp) = extract_valid_until(&tbs_data) {
        // FIXME: this doesn't work (TIMEZONE is wrong)
        println!("valid_until_unix_timestamp: {}", valid_until_unix_timestamp);
    } else {
        println!("valid_until_unix_timestamp not found");
    }

    let dob_info = find_value_digest_info(&namespaces, &mso, &tbs_data, "birth_date")/* .unwrap() FIXME*/;
    println!("dob_info: {:?}", dob_info);

    // begin output of prover's inputs
    let mut prover_inputs = Map::new();
    println!("prover_inputs: {:?}", padded_m);
    prover_inputs.insert("message".to_string(), serde_json::json!(padded_m));
    // TODO: add more prover inputs
    
    // TODO: continue re-impl python script from here

    let signature_bytes = issuer_auth.signature.clone();
    let signature_len = signature_bytes.len();
    println!(
        "signature ({} bytes):\n{:?}\n",
        signature_len, signature_bytes
    );

    let verification_result =
            issuer_auth
            .verify::<VerifyingKey, Signature>(&issuer_pub_key, None, None);
    println!(
        "mDL signature verification result: {:?}\n",
        verification_result
    );

    // save prover_inputs to a file
    let prover_inputs_json = serde_json::to_string_pretty(&prover_inputs).unwrap();
    std::fs::write(&args.prover_inputs, prover_inputs_json).unwrap();
    println!("Prover inputs saved to: {}\n", args.prover_inputs);
}

